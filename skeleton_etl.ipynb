{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----Patient ETL\n",
    "import psycopg2\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "from datetime import datetime, timezone\n",
    "#import datetime  # module\n",
    "#from datetime import datetime as dt  # class, aliased to avoid conflict\n",
    "#from datetime import datetime as tz\n",
    "#import datetime\n",
    "import json\n",
    "\n",
    "# Path to your service account JSON key\n",
    "key_path = \"/Users/toniventura/keys/bq_key.json\" \n",
    "\n",
    "# Create credentials and BigQuery client\n",
    "#credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "\n",
    "# Postgres config\n",
    "PG_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"fhir\",\n",
    "    \"user\": \"toniventura\",\n",
    "    \"password\": \"fhir_project\"\n",
    "}\n",
    "#records =[]\n",
    "\n",
    "# BigQuery config\n",
    "#BQ_PROJECT = \"your-gcp-project\"\n",
    "BQ_PROJECT = \"fhir-synthea-data\"\n",
    "BQ_DATASET = \"fhir_curated\"\n",
    "#client = bigquery.Client(project=BQ_PROJECT)\n",
    "client = bigquery.Client(project=\"fhir-synthea-data\", credentials=credentials)\n",
    "#client = bigquery.Client(project=BQ_PROJECT, credentials=credentials)\n",
    "dataset_ref = bigquery.Dataset(f\"{BQ_PROJECT}.{BQ_DATASET}\")\n",
    "\n",
    "# Helper: fetch staged data\n",
    "def fetch_staged_data(table, batch_size=10000):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**PG_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        #cur.execute(f\"SELECT * FROM fhir_staging.{table}\")\n",
    "        cur.execute(\"SELECT * FROM fhir_staging.patients_fhir_raw LIMIT 5;\")\n",
    "        while True:\n",
    "            rows = cur.fetchmany(batch_size)\n",
    "            print(f\"rows: {rows}\")\n",
    "            if not rows:\n",
    "                break\n",
    "            yield rows\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Postgres connection or query failed: {e}\")\n",
    "        \n",
    "\n",
    "\n",
    "# Helper: insert dataframe into BigQuery\n",
    "def insert_to_bq(df, table_name):\n",
    "    table_id = f\"{BQ_PROJECT}.{BQ_DATASET}.{table_name}\"\n",
    "    job = client.load_table_from_dataframe(df, table_id)\n",
    "    job.result()  # wait for completion\n",
    "\n",
    "# Example: Transform & load Patients\n",
    "def transform_patients(rows):\n",
    "    #print(\"transforming data\")\n",
    "    records = []\n",
    "    print(f\"rows: {len(rows)}\")\n",
    "    for r in rows:\n",
    "        print(\"inside loop\")\n",
    "        rid, resource = r[1], r[2] # adjust index if needed\n",
    "        #print(f\"rid: {rid}\")\n",
    "        #print(f\"resource: {resource}\")\n",
    "        #birth_date = resource.get(\"birthdate\")\n",
    "        records.append({\n",
    "            \"patient_id\": rid,\n",
    "            \"first_name\": resource.get(\"name\", [{}])[0].get(\"given\", [\"\"])[0],\n",
    "            \"last_name\": resource.get(\"name\", [{}])[0].get(\"family\", \"\"),\n",
    "            #\"birth_date\": datetime.date.fromisoformat(resource.get(\"birthDate\"))\n",
    "                #if resource.get(\"birthDate\") else None,\n",
    "            \"birth_date\": datetime.fromisoformat(resource.get(\"birthDate\"))\n",
    "                if resource.get(\"birthDate\") else None,\n",
    "            \"gender\": resource.get(\"gender\"),\n",
    "            #\"load_timestamp\" : datetime.datetime.utcnow()\n",
    "            \"load_timestamp\": datetime.now(timezone.utc)\n",
    "        })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Main ETL loop\n",
    "def etl_patients():\n",
    "    try:\n",
    "        for batch in tqdm(fetch_staged_data(\"patients_fhir_raw\")):\n",
    "            df = transform_patients(batch)\n",
    "            if not df.empty:\n",
    "                insert_to_bq(df, \"patients\")\n",
    "                print(\"***Inserting***\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in patients ETL: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_patients()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aacb4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'system': 'http://hl7.org/fhir/sid/us-npi', 'value': '9999928192'}\n",
      "system: http://hl7.org/fhir/sid/us-npi\n",
      "value: 9999928192\n",
      "---- Results ----\n",
      "NPI: 9999928192\n",
      "License Number: None\n",
      "Other IDs: []\n",
      "***Inserted batch***\n"
     ]
    }
   ],
   "source": [
    "#---Practitioner ETL\n",
    "import psycopg2\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "# Path to your service account JSON key\n",
    "key_path = \"/Users/toniventura/keys/bq_key.json\"\n",
    "\n",
    "# Create credentials and BigQuery client\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "BQ_PROJECT = \"fhir-synthea-data\"\n",
    "BQ_DATASET = \"fhir_curated\"\n",
    "client = bigquery.Client(project=BQ_PROJECT, credentials=credentials)\n",
    "\n",
    "# Postgres config\n",
    "PG_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"fhir\",\n",
    "    \"user\": \"toniventura\",\n",
    "    \"password\": \"fhir_project\"\n",
    "}\n",
    "\n",
    "# Helper: fetch staged data\n",
    "def fetch_staged_data(table, batch_size=10000):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**PG_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"SELECT * FROM fhir_staging.{table} LIMIT 5;\")\n",
    "        while True:\n",
    "            rows = cur.fetchmany(batch_size)\n",
    "            if not rows:\n",
    "                break\n",
    "            yield rows\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Postgres connection or query failed: {e}\")\n",
    "\n",
    "# Helper: insert dataframe into BigQuery\n",
    "def insert_to_bq(df, table_name):\n",
    "    table_id = f\"{BQ_PROJECT}.{BQ_DATASET}.{table_name}\"\n",
    "    job = client.load_table_from_dataframe(df, table_id)\n",
    "    job.result()\n",
    "\n",
    "# Transform Practitioners\n",
    "def transform_practitioners(rows):\n",
    "    records = []\n",
    "    for r in rows:\n",
    "        rid, resource = r[1], r[2]  # adjust index if needed\n",
    "\n",
    "        #Initialize variables so they exist even if not found\n",
    "        npi = None\n",
    "        license_number = None\n",
    "        other_ids = []\n",
    "\n",
    "    for ident in resource.get(\"identifier\", []):\n",
    "        # Debugging: show the whole identifier object\n",
    "        pprint.pprint(ident)\n",
    "\n",
    "        system = ident.get(\"system\")\n",
    "        value = ident.get(\"value\")\n",
    "\n",
    "        print(f\"system: {system}\")\n",
    "        print(f\"value: {value}\")\n",
    "\n",
    "        if system == \"http://hl7.org/fhir/sid/us-npi\":\n",
    "            npi = value\n",
    "        elif system == \"http://example.org/license-number\":\n",
    "            license_number = value\n",
    "        else:\n",
    "            other_ids.append(value)\n",
    "\n",
    "\n",
    "        print(\"---- Results ----\")\n",
    "        print(f\"NPI: {npi}\")\n",
    "        print(f\"License Number: {license_number}\")\n",
    "        print(f\"Other IDs: {other_ids}\")\n",
    "        name_info = resource.get(\"name\", [{}])[0]\n",
    "\n",
    "        records.append({\n",
    "            \"practitioner_id\": rid,\n",
    "            \"first_name\": name_info.get(\"given\", [\"\"])[0],\n",
    "            \"last_name\": name_info.get(\"family\", \"\"),\n",
    "            \"prefix\": name_info.get(\"prefix\", [\"\"])[0] if name_info.get(\"prefix\") else None,\n",
    "            \"gender\": resource.get(\"gender\"),\n",
    "            #\"birth_date\": datetime.fromisoformat(resource.get(\"birthDate\")) if resource.get(\"birthDate\") else None,\n",
    "            \"npi\": npi,\n",
    "            \"license_number\": license_number,\n",
    "            \"primary_email\": next((t.get(\"value\") for t in resource.get(\"telecom\", []) if t.get(\"system\") == \"email\"), None),\n",
    "            \"primary_phone\": next((t.get(\"value\") for t in resource.get(\"telecom\", []) if t.get(\"system\") == \"phone\"), None),\n",
    "            \"load_timestamp\": datetime.now(timezone.utc)\n",
    "        })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Main ETL loop\n",
    "def etl_practitioners():\n",
    "    try:\n",
    "        for batch in fetch_staged_data(\"practitioners_fhir_raw\"):\n",
    "            df = transform_practitioners(batch)\n",
    "            if not df.empty:\n",
    "                insert_to_bq(df, \"practitioners\")\n",
    "                print(\"***Inserted batch***\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in practitioners ETL: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_practitioners()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad0b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208D00000X\n",
      "General Practice Physician\n",
      "General Practice Physician\n",
      "208D00000X\n",
      "208D00000X\n",
      "General Practice Physician\n",
      "General Practice Physician\n",
      "208D00000X\n",
      "208D00000X\n",
      "General Practice Physician\n",
      "General Practice Physician\n",
      "208D00000X\n",
      "208D00000X\n",
      "General Practice Physician\n",
      "General Practice Physician\n",
      "208D00000X\n",
      "208D00000X\n",
      "General Practice Physician\n",
      "General Practice Physician\n",
      "208D00000X\n",
      "***Inserted batch***\n"
     ]
    }
   ],
   "source": [
    "#---Practitioner Roles ETL\n",
    "import psycopg2\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "# Path to your service account JSON key\n",
    "key_path = \"/Users/toniventura/keys/bq_key.json\"\n",
    "\n",
    "# Create credentials and BigQuery client\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "BQ_PROJECT = \"fhir-synthea-data\"\n",
    "BQ_DATASET = \"fhir_curated\"\n",
    "client = bigquery.Client(project=BQ_PROJECT, credentials=credentials)\n",
    "\n",
    "# Postgres config\n",
    "PG_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"fhir\",\n",
    "    \"user\": \"toniventura\",\n",
    "    \"password\": \"fhir_project\"\n",
    "}\n",
    "\n",
    "def insert_to_bq(df, table_name):\n",
    "    table_id = f\"{BQ_PROJECT}.{BQ_DATASET}.{table_name}\"\n",
    "    job = client.load_table_from_dataframe(df, table_id)\n",
    "    job.result()\n",
    "\n",
    "def fetch_staged_data(table, batch_size=10000):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**PG_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"SELECT * FROM fhir_staging.{table} LIMIT 5;\")\n",
    "        while True:\n",
    "            rows = cur.fetchmany(batch_size)\n",
    "            if not rows:\n",
    "                break\n",
    "            yield rows\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Postgres connection or query failed: {e}\")\n",
    "\n",
    "# Helper: insert dataframe into BigQuery\n",
    "def insert_to_bq(df, table_name):\n",
    "    table_id = f\"{BQ_PROJECT}.{BQ_DATASET}.{table_name}\"\n",
    "    job = client.load_table_from_dataframe(df, table_id)\n",
    "    job.result()\n",
    "\n",
    "# Transform Practitioners\n",
    "def transform_practitioner_roles(rows):\n",
    "    records = []\n",
    "    for r in rows:\n",
    "        rid, resource = r[1], r[2]\n",
    "\n",
    "        # Initialize columns\n",
    "        specialty_text = resource.get(\"specialty\", {})[0].get(\"text\")\n",
    "        #specialty_code = resource.get(\"specialty\", {})[0].get(\"code\",[{}][0].get(\"coding\",[{}][0].get(\"code\")))\n",
    "        specialty_code = resource.get(\"specialty\", [{}])[0].get(\"coding\", [{}])[0].get(\"code\")\n",
    "        role_text = resource.get(\"code\", [{}])[0].get(\"text\")\n",
    "        role_code = resource.get(\"code\", [{}])[0].get(\"coding\", [{}])[0].get(\"code\")\n",
    "        \n",
    "        print(specialty_code)\n",
    "        print(specialty_text)\n",
    "        print(role_text)\n",
    "        print(role_code)\n",
    "\n",
    "        \n",
    "\n",
    "        records.append({\n",
    "            \"practitioner_role_id\": rid,\n",
    "            \"practitioner_npi\": resource.get(\"practitioner\", {}).get(\"identifier\").get(\"value\"),\n",
    "            \"organization_id\": resource.get(\"organization\", {}).get(\"identifier\").get(\"value\"),\n",
    "            \"specialty_code\": specialty_code,\n",
    "            \"specialty_text\": specialty_text,\n",
    "            \"role_text\" : role_text, \n",
    "            \"role_code\": role_code, \n",
    "            #                 if resource.get(\"telecom\") and resource[\"telecom\"][0].get(\"system\")==\"email\" else None,\n",
    "            #\"role_text\": resource.get(\"telecom\", [{}])[0].get(\"value\") \n",
    "                              #if resource.get(\"telecom\") and resource[\"telecom\"][0].get(\"system\")==\"phone\" else None,\n",
    "            \"load_timestamp\": datetime.now(timezone.utc)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "# Main ETL loop\n",
    "def etl_practitioner_roles():\n",
    "    try:\n",
    "        for batch in fetch_staged_data(\"practitioner_roles_fhir_raw\"):\n",
    "            df = transform_practitioner_roles(batch)\n",
    "            if not df.empty:\n",
    "                insert_to_bq(df, \"practitioner_roles\")\n",
    "                print(\"***Inserted batch***\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in practitioner roles ETL: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_practitioner_roles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75baae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 rows to fhir-synthea-data.fhir_curated.observations\n",
      "***Inserted batch***\n"
     ]
    }
   ],
   "source": [
    "#---Observations ETL\n",
    "import psycopg2\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "import pprint\n",
    "import dateutil.parser  # optional, for robust ISO parsing\n",
    "\n",
    "# Path to your service account JSON key\n",
    "key_path = \"/Users/toniventura/keys/bq_key.json\"\n",
    "\n",
    "# Create credentials and BigQuery client\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "BQ_PROJECT = \"fhir-synthea-data\"\n",
    "BQ_DATASET = \"fhir_curated\"\n",
    "client = bigquery.Client(project=BQ_PROJECT, credentials=credentials)\n",
    "\n",
    "# Postgres config\n",
    "PG_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"fhir\",\n",
    "    \"user\": \"toniventura\",\n",
    "    \"password\": \"fhir_project\"\n",
    "}\n",
    "\n",
    "def insert_to_bq(df, table_name):\n",
    "    table_id = f\"{BQ_PROJECT}.{BQ_DATASET}.{table_name}\"\n",
    "    job = client.load_table_from_dataframe(df, table_id)\n",
    "    job.result()\n",
    "    print(f\"Loaded {job.output_rows} rows to {table_id}\")\n",
    "\n",
    "\n",
    "\n",
    "# Helper: fetch staged data\n",
    "def fetch_staged_data(table, batch_size=10000):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**PG_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"SELECT * FROM fhir_staging.{table} LIMIT 5;\")\n",
    "        while True:\n",
    "            rows = cur.fetchmany(batch_size)\n",
    "            if not rows:\n",
    "                break\n",
    "            yield rows\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Postgres connection or query failed: {e}\")\n",
    "\n",
    "# Transform Practitioners\n",
    "def transform_observations(rows):\n",
    "    records = []\n",
    "    for r in rows:\n",
    "        rid, resource = r[1], r[2]\n",
    "\n",
    "        # Initialize columns\n",
    "        codings  = resource.get(\"code\", {}).get(\"coding\", [])\n",
    "        code_text = resource.get(\"code\", {}).get(\"text\")\n",
    "\n",
    "        status = resource.get(\"status\") if codings else None\n",
    "        system = codings[0].get(\"system\")if codings else None\n",
    "        code = codings[0].get(\"code\") if codings else None\n",
    "        \n",
    "        codings_struct = [\n",
    "            {\n",
    "                \"system\" : c.get(\"system\"), \n",
    "                \"code\" : c.get(\"code\"), \n",
    "                \"display\": c.get(\"display\")\n",
    "                \n",
    "            }for c in codings\n",
    "        ]\n",
    "\n",
    "        value_numeric = None\n",
    "        unit = None\n",
    "        value_text = None\n",
    "        value_codings = []\n",
    "\n",
    "        if \"valueQuantity\" in resource:\n",
    "            q = resource[\"valueQuantity\"]\n",
    "            value_numeric = q.get(\"value\")\n",
    "            unit = q.get(\"unit\")\n",
    "            # system/code available but usually redundant here\n",
    "\n",
    "        elif \"valueString\" in resource:\n",
    "            value_text = resource[\"valueString\"]\n",
    "\n",
    "        elif \"valueCodeableConcept\" in resource:\n",
    "            cc = resource[\"valueCodeableConcept\"]\n",
    "            # Store text in value_text for quick querying\n",
    "            value_text = cc.get(\"text\")\n",
    "            # Capture codings for full fidelity\n",
    "            for c in cc.get(\"coding\", []):\n",
    "                value_codings.append({\n",
    "                \"system\": c.get(\"system\"),\n",
    "                \"code\": c.get(\"code\"),\n",
    "                \"display\": c.get(\"display\")\n",
    "             })\n",
    "\n",
    "        elif \"valueDateTime\" in resource:\n",
    "            value_text = resource[\"valueDateTime\"]  # or a dedicated column\n",
    "\n",
    "        elif \"valuePeriod\" in resource:\n",
    "            value_text = json.dumps(resource[\"valuePeriod\"])  # or expand into start/end columns\n",
    "\n",
    "        patient_id_ref = resource.get(\"subject\", {}).get(\"reference\")\n",
    "        patient_id = patient_id_ref.split(\":\")[-1]\n",
    "\n",
    "        encounter_id_ref = resource.get(\"encounter\",{}).get(\"reference\")\n",
    "        encounter_id = encounter_id_ref.split(\":\")[-1]\n",
    "\n",
    "        effective_date_str = resource.get(\"effectiveDateTime\")\n",
    "        effective_date = None\n",
    "\n",
    "        if effective_date_str:\n",
    "            effective_datetime = dateutil.parser.isoparse(effective_date_str)\n",
    "        \n",
    "        records.append({\n",
    "            \"observation_id\": rid,\n",
    "            \"status\" : status,\n",
    "            \"obs_code\": code,\n",
    "            \"system\": system,\n",
    "            \"obs_code_text\": code_text,\n",
    "            \"codings\": codings_struct,\n",
    "            \"value_numeric\": value_numeric, \n",
    "            \"value_text\" : value_text,\n",
    "            \"unit\" : unit,\n",
    "            \"value_codings\" : value_codings, \n",
    "            \"patient_id\" : patient_id,\n",
    "            \"encounter_id\" : encounter_id,\n",
    "            \"effective_datetime\": effective_date, #not inserting\n",
    "            \"load_timestamp\": datetime.now(timezone.utc) \n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "# Main ETL loop\n",
    "def etl_observations():\n",
    "    try:\n",
    "        for batch in fetch_staged_data(\"observations_fhir_raw\"):\n",
    "            df = transform_observations(batch)\n",
    "            if not df.empty:\n",
    "                insert_to_bq(df, \"observations\")\n",
    "                print(\"***Inserted batch***\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in observations ETL: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_observations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a69ce39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 rows to fhir-synthea-data.fhir_curated.conditions\n",
      "***Inserted batch***\n"
     ]
    }
   ],
   "source": [
    "#---Conditions ETL\n",
    "import psycopg2\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "import pprint\n",
    "import dateutil.parser  # optional, for robust ISO parsing\n",
    "\n",
    "# Path to your service account JSON key\n",
    "key_path = \"/Users/toniventura/keys/bq_key.json\"\n",
    "\n",
    "# Create credentials and BigQuery client\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "BQ_PROJECT = \"fhir-synthea-data\"\n",
    "BQ_DATASET = \"fhir_curated\"\n",
    "client = bigquery.Client(project=BQ_PROJECT, credentials=credentials)\n",
    "\n",
    "# Postgres config\n",
    "PG_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"fhir\",\n",
    "    \"user\": \"toniventura\",\n",
    "    \"password\": \"fhir_project\"\n",
    "}\n",
    "\n",
    "def insert_to_bq(df, table_name):\n",
    "    table_id = f\"{BQ_PROJECT}.{BQ_DATASET}.{table_name}\"\n",
    "    job = client.load_table_from_dataframe(df, table_id)\n",
    "    job.result()\n",
    "    print(f\"Loaded {job.output_rows} rows to {table_id}\")\n",
    "\n",
    "\n",
    "\n",
    "# Helper: fetch staged data\n",
    "def fetch_staged_data(table, batch_size=10000):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**PG_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"SELECT * FROM fhir_staging.{table} LIMIT 5;\")\n",
    "        while True:\n",
    "            rows = cur.fetchmany(batch_size)\n",
    "            if not rows:\n",
    "                break\n",
    "            yield rows\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Postgres connection or query failed: {e}\")\n",
    "\n",
    "# Transform Practitioners\n",
    "def transform_conditions(rows):\n",
    "    records = []\n",
    "    for r in rows:\n",
    "        rid, resource = r[1], r[2]\n",
    "\n",
    "        # Initialize columns\n",
    "        codings  = resource.get(\"code\", {}).get(\"coding\", [])\n",
    "        code_text = resource.get(\"code\", {}).get(\"text\")\n",
    "\n",
    "        status = resource.get(\"status\") if codings else None\n",
    "        system = codings[0].get(\"system\")if codings else None\n",
    "        code = codings[0].get(\"code\") if codings else None\n",
    "        \n",
    "        codings_struct = [\n",
    "            {\n",
    "                \"system\" : c.get(\"system\"), \n",
    "                \"code\" : c.get(\"code\"), \n",
    "                \"display\": c.get(\"display\")\n",
    "                \n",
    "            }for c in codings\n",
    "        ]\n",
    "\n",
    "        category = None\n",
    "        category_text = None\n",
    "\n",
    "        if resource.get(\"category\"):\n",
    "            first_category = resource[\"category\"][0][\"coding\"][0]  # first category -> first coding\n",
    "            category = first_category.get(\"code\")\n",
    "            category_text = first_category.get(\"display\")\n",
    "        else:\n",
    "            category = None\n",
    "            category_text = None\n",
    "\n",
    "        # Nested array for full fidelity\n",
    "        category_codings = []\n",
    "        for cat in resource.get(\"category\", []):\n",
    "            for coding in cat.get(\"coding\", []):\n",
    "                category_codings.append({\n",
    "                \"system\": coding.get(\"system\"),\n",
    "                \"code\": coding.get(\"code\"),\n",
    "                \"display\": coding.get(\"display\")\n",
    "             })\n",
    "\n",
    "    \n",
    "        patient_id_ref = resource.get(\"subject\", {}).get(\"reference\")\n",
    "        patient_id = patient_id_ref.split(\":\")[-1]\n",
    "\n",
    "        encounter_id_ref = resource.get(\"encounter\",{}).get(\"reference\")\n",
    "        encounter_id = encounter_id_ref.split(\":\")[-1]\n",
    "\n",
    "        onset_date_str = resource.get(\"effectiveDateTime\")\n",
    "        onset_date_time = None\n",
    "\n",
    "        if onset_date_str:\n",
    "            onset_date_time = dateutil.parser.isoparse(onset_date_str)\n",
    "        \n",
    "        records.append({\n",
    "            \"condition_id\": rid,\n",
    "            \"clinical_status\" : status,\n",
    "            \"code\": code,\n",
    "            \"code_system\": system,\n",
    "            \"code_text\": code_text,\n",
    "            \"codings\": codings_struct,\n",
    "            \"category_code\": category,\n",
    "            \"category\": category_text,\n",
    "            \"category_codings\": category_codings,\n",
    "            \"patient_id\" : patient_id,\n",
    "            \"encounter_id\" : encounter_id,\n",
    "            \"onset_date\": onset_date_time, #not inserting\n",
    "            \"load_timestamp\": datetime.now(timezone.utc) \n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "# Main ETL loop\n",
    "def etl_conditions():\n",
    "    try:\n",
    "        for batch in fetch_staged_data(\"conditions_fhir_raw\"):\n",
    "            df = transform_conditions(batch)\n",
    "            if not df.empty:\n",
    "                insert_to_bq(df, \"conditions\")\n",
    "                print(\"***Inserted batch***\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in conditions ETL: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_conditions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eb9efc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys: dict_keys(['id', 'use', 'item', 'type', 'total', 'status', 'created', 'patient', 'priority', 'provider', 'insurance', 'prescription', 'resourceType', 'billablePeriod'])\n",
      "use: claim\n",
      "status: active\n",
      "patient_id: 9cfbd2b4-5eff-91db-1a93-777a9b86738f\n",
      "dictionary\n",
      "Dictionary....type: pharmacy\n",
      "type_info: pharmacy\n",
      "550.36\n",
      "USD\n",
      "2004-11-26 13:41:41+00:00\n",
      "2004-11-26 13:56:41+00:00\n",
      "date_created: 2004-11-26 13:56:41+00:00\n",
      "priority_code: normal\n",
      "facility_obj: None\n",
      "Insurance seq: 1\n",
      "Focal: True\n",
      "Coverage NO_INSURANCE\n",
      "Items\n",
      "Item sequence: None\n",
      "service_period: {}\n",
      "start: None\n",
      "end: None\n",
      "item_type: None\n",
      "-------------------location: [{'facility_id': 'None', 'system': 'None', 'code': 'None', 'display': 'None'}]\n",
      "encounter:None\n",
      "net_value: 0\n",
      "net_currency: USD\n",
      "item_text: None\n",
      "keys: dict_keys(['id', 'use', 'item', 'type', 'total', 'status', 'created', 'patient', 'facility', 'priority', 'provider', 'diagnosis', 'insurance', 'resourceType', 'billablePeriod'])\n",
      "use: claim\n",
      "status: active\n",
      "patient_id: 9cfbd2b4-5eff-91db-1a93-777a9b86738f\n",
      "dictionary\n",
      "Dictionary....type: professional\n",
      "type_info: professional\n",
      "85.55\n",
      "USD\n",
      "2004-11-26 13:41:41+00:00\n",
      "2004-11-26 13:56:41+00:00\n",
      "date_created: 2004-11-26 13:56:41+00:00\n",
      "priority_code: normal\n",
      "facility_obj: {'display': 'FRANCISCAN HOSPITAL FOR CHILDREN INC', 'reference': 'Location?identifier=https://github.com/synthetichealth/synthea|903e1531-4e7b-3e59-9819-f42f3f75236a'}\n",
      "facility_reference: Location?identifier=https://github.com/synthetichealth/synthea\n",
      "facility_id: 903e1531-4e7b-3e59-9819-f42f3f75236a\n",
      "Insurance seq: 1\n",
      "Focal: True\n",
      "Coverage NO_INSURANCE\n",
      "Items\n",
      "Item sequence: None\n",
      "service_period: {}\n",
      "start: None\n",
      "end: None\n",
      "item_type: None\n",
      "-------------------location: [{'facility_id': '903e1531-4e7b-3e59-9819-f42f3f75236a', 'system': 'None', 'code': 'None', 'display': 'None'}]\n",
      "encounter:None\n",
      "net_value: 0\n",
      "net_currency: USD\n",
      "item_text: None\n",
      "keys: dict_keys(['id', 'use', 'item', 'type', 'total', 'status', 'created', 'patient', 'facility', 'priority', 'provider', 'diagnosis', 'insurance', 'resourceType', 'billablePeriod'])\n",
      "use: claim\n",
      "status: active\n",
      "patient_id: 9cfbd2b4-5eff-91db-1a93-777a9b86738f\n",
      "dictionary\n",
      "Dictionary....type: institutional\n",
      "type_info: institutional\n",
      "17189.78\n",
      "USD\n",
      "2004-11-26 13:41:41+00:00\n",
      "2004-11-26 15:05:42+00:00\n",
      "date_created: 2004-11-26 15:05:42+00:00\n",
      "priority_code: normal\n",
      "facility_obj: {'display': 'SANCTA MARIA NURSING FACILITY', 'reference': 'Location?identifier=https://github.com/synthetichealth/synthea|eb61e028-1323-3300-8843-e02dbc8237d5'}\n",
      "facility_reference: Location?identifier=https://github.com/synthetichealth/synthea\n",
      "facility_id: eb61e028-1323-3300-8843-e02dbc8237d5\n",
      "Insurance seq: 1\n",
      "Focal: True\n",
      "Coverage NO_INSURANCE\n",
      "Items\n",
      "Item sequence: None\n",
      "service_period: {}\n",
      "start: None\n",
      "end: None\n",
      "item_type: None\n",
      "-------------------location: [{'facility_id': 'eb61e028-1323-3300-8843-e02dbc8237d5', 'system': 'None', 'code': 'None', 'display': 'None'}]\n",
      "encounter:None\n",
      "net_value: 0\n",
      "net_currency: USD\n",
      "item_text: None\n",
      "keys: dict_keys(['id', 'use', 'item', 'type', 'total', 'status', 'created', 'patient', 'priority', 'provider', 'insurance', 'prescription', 'resourceType', 'billablePeriod'])\n",
      "use: claim\n",
      "status: active\n",
      "patient_id: 9cfbd2b4-5eff-91db-1a93-777a9b86738f\n",
      "dictionary\n",
      "Dictionary....type: pharmacy\n",
      "type_info: pharmacy\n",
      "37.76\n",
      "USD\n",
      "2004-12-04 18:41:41+00:00\n",
      "2004-12-04 19:03:18+00:00\n",
      "date_created: 2004-12-04 19:03:18+00:00\n",
      "priority_code: normal\n",
      "facility_obj: None\n",
      "Insurance seq: 1\n",
      "Focal: True\n",
      "Coverage NO_INSURANCE\n",
      "Items\n",
      "Item sequence: None\n",
      "service_period: {}\n",
      "start: None\n",
      "end: None\n",
      "item_type: None\n",
      "-------------------location: [{'facility_id': 'None', 'system': 'None', 'code': 'None', 'display': 'None'}]\n",
      "encounter:None\n",
      "net_value: 0\n",
      "net_currency: USD\n",
      "item_text: None\n",
      "keys: dict_keys(['id', 'use', 'item', 'type', 'total', 'status', 'created', 'patient', 'facility', 'priority', 'provider', 'insurance', 'resourceType', 'billablePeriod'])\n",
      "use: claim\n",
      "status: active\n",
      "patient_id: 9cfbd2b4-5eff-91db-1a93-777a9b86738f\n",
      "dictionary\n",
      "Dictionary....type: professional\n",
      "type_info: professional\n",
      "516.95\n",
      "USD\n",
      "2004-12-04 18:41:41+00:00\n",
      "2004-12-04 19:03:18+00:00\n",
      "date_created: 2004-12-04 19:03:18+00:00\n",
      "priority_code: normal\n",
      "facility_obj: {'display': 'FRANCISCAN HOSPITAL FOR CHILDREN INC', 'reference': 'Location?identifier=https://github.com/synthetichealth/synthea|903e1531-4e7b-3e59-9819-f42f3f75236a'}\n",
      "facility_reference: Location?identifier=https://github.com/synthetichealth/synthea\n",
      "facility_id: 903e1531-4e7b-3e59-9819-f42f3f75236a\n",
      "Insurance seq: 1\n",
      "Focal: True\n",
      "Coverage NO_INSURANCE\n",
      "Items\n",
      "Item sequence: None\n",
      "service_period: {}\n",
      "start: None\n",
      "end: None\n",
      "item_type: None\n",
      "-------------------location: [{'facility_id': '903e1531-4e7b-3e59-9819-f42f3f75236a', 'system': 'None', 'code': 'None', 'display': 'None'}]\n",
      "encounter:None\n",
      "net_value: 0\n",
      "net_currency: USD\n",
      "item_text: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error converting Pandas column with name: \"diagnoses\" and datatype: \"object\" to an appropriate pyarrow datatype: Array, ListArray, or StructArray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in claims ETL: Error converting Pandas column with name: \"diagnoses\" and datatype: \"object\" to an appropriate pyarrow datatype: Array, ListArray, or StructArray\n"
     ]
    }
   ],
   "source": [
    "#---Claims ETL\n",
    "import psycopg2\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "import pprint\n",
    "import dateutil.parser  # optional, for robust ISO parsing\n",
    "\n",
    "# Path to your service account JSON key\n",
    "key_path = \"/Users/toniventura/keys/bq_key.json\"\n",
    "\n",
    "# Create credentials and BigQuery client\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "BQ_PROJECT = \"fhir-synthea-data\"\n",
    "BQ_DATASET = \"fhir_curated\"\n",
    "client = bigquery.Client(project=BQ_PROJECT, credentials=credentials)\n",
    "\n",
    "# Postgres config\n",
    "PG_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"fhir\",\n",
    "    \"user\": \"toniventura\",\n",
    "    \"password\": \"fhir_project\"\n",
    "}\n",
    "\n",
    "def insert_to_bq(df, table_name):\n",
    "    table_id = f\"{BQ_PROJECT}.{BQ_DATASET}.{table_name}\"\n",
    "    job = client.load_table_from_dataframe(df, table_id)\n",
    "    job.result()\n",
    "    print(f\"Loaded {job.output_rows} rows to {table_id}\")\n",
    "\n",
    "\n",
    "\n",
    "# Helper: fetch staged data\n",
    "def fetch_staged_data(table, batch_size=10000):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**PG_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"SELECT * FROM fhir_staging.{table} LIMIT 5;\")\n",
    "        while True:\n",
    "            rows = cur.fetchmany(batch_size)\n",
    "            if not rows:\n",
    "                break\n",
    "            yield rows\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Postgres connection or query failed: {e}\")\n",
    "\n",
    "# Transform Practitioners\n",
    "def transform_claims(rows):\n",
    "    records = []\n",
    "    for r in rows:\n",
    "        rid, resource = r[1], r[2]\n",
    "\n",
    "        keys= resource.keys()\n",
    "\n",
    "        print(f\"keys: {keys}\")\n",
    "\n",
    "        use = resource.get(\"use\")\n",
    "        print(f\"use: {use}\")\n",
    "\n",
    "        status = resource.get(\"status\")\n",
    "        print(f\"status: {status}\")\n",
    "\n",
    "        patient_id = resource.get(\"patient\", {}).get(\"reference\").split(\":\")[-1]\n",
    "        print(f\"patient_id: {patient_id}\")\n",
    "        type = \"None\"\n",
    "        type_info = resource.get(\"type\", {})\n",
    "        if isinstance (type_info, dict):\n",
    "            print(\"dictionary\")\n",
    "            codings = type_info.get(\"coding\")\n",
    "            if codings:\n",
    "                type = codings[0].get(\"code\")\n",
    "                print(f\"Dictionary....type: {type}\")\n",
    "        \n",
    "        elif isinstance(type_info, list) and type_info:\n",
    "            first = type_info[0]\n",
    "            if isinstance(first, dict):\n",
    "                codings = first.get(\"coding\")\n",
    "                if codings:\n",
    "                    type_info = codings[0].get(\"code\")\n",
    "                    print(f\"type_info...type_info\")\n",
    "        else:\n",
    "            type = None\n",
    "        print(f\"type_info: {type}\")\n",
    "\n",
    "        total_value = resource.get(\"total\",{}).get(\"value\")\n",
    "        print(total_value)\n",
    "        total_currency = resource.get(\"total\", {}).get(\"currency\")\n",
    "        print(total_currency)\n",
    "\n",
    "        billable_start = None\n",
    "        billable_start = pd.to_datetime(resource.get(\"billablePeriod\", {}).get(\"start\"), utc=True)\n",
    "        print(billable_start)\n",
    "        billable_end = None\n",
    "        billable_end = pd.to_datetime(resource.get(\"billablePeriod\", {}).get(\"end\"), utc=True)\n",
    "        print(billable_end)\n",
    "\n",
    "        date_created = pd.to_datetime(resource.get(\"created\"), utc=True)\n",
    "        print(f\"date_created: {date_created}\")\n",
    "\n",
    "        billing_provider = []\n",
    "\n",
    "        provider_obj = resource.get(\"provider\", {})\n",
    "        if provider_obj:  # only add if provider exists\n",
    "            provider_reference = provider_obj.get(\"reference\", \"\")\n",
    "            provider_reference_id = provider_reference.split(\"|\")[-1] if \"|\" in provider_reference else provider_reference\n",
    "            provider_reference_type = provider_reference.split(\"?\")[0] if \"?\" in provider_reference else None\n",
    "            provider_display = provider_obj.get(\"display\")\n",
    "\n",
    "        '''billing_provider.append({\n",
    "            \"provider_reference_id\": provider_reference_id,\n",
    "            \"provider_reference_type\": provider_reference_type,\n",
    "            \"provider_display\": provider_display\n",
    "        })'''\n",
    "\n",
    "        # ensure it is always a list, even if empty\n",
    "\n",
    "        priority_codings= resource.get(\"priority\", {}).get(\"coding\",[]) \n",
    "        priority_code = priority_codings[0].get(\"code\")\n",
    "        print(f\"priority_code: {priority_code}\")\n",
    "\n",
    "        facility_json = resource.get(\"facility\")\n",
    "        print(f\"facility_obj: {facility_json}\")\n",
    "        #print(f\"facility_json: {facility_json}\")\n",
    "        facility = []\n",
    "        facility_reference = \"None\"\n",
    "        facility_id = \"None\"\n",
    "        facility_display = \"None\"\n",
    "        \n",
    "        if facility_json:\n",
    "            facility_reference_complete = facility_json.get(\"reference\")\n",
    "            facility_display = facility_json.get(\"display\")\n",
    "\n",
    "        #print(f\"facility: {facility_reference_complete}\")\n",
    "            if facility_reference_complete:\n",
    "                facility_reference = facility_reference_complete.split(\"|\")[0]\n",
    "                print(f\"facility_reference: {facility_reference}\")\n",
    "            \n",
    "                facility_id = facility_reference_complete.split(\"|\")[-1]\n",
    "                print(f\"facility_id: {facility_id}\")\n",
    "            else:\n",
    "                facility_reference = \"None\"\n",
    "                facility_id = \"None\"\n",
    "        facility.append({\n",
    "            \"facility_reference\": facility_reference,\n",
    "            #\"facility_reference\": facility_json.get(\"reference\"),\n",
    "            \"facility_id\": facility_id,\n",
    "            \"facility_display\" : facility_display  \n",
    "        })\n",
    "\n",
    "        insurances = resource.get(\"insurance\",[])\n",
    "        all_insurances = []\n",
    "\n",
    "        for insurance in insurances:\n",
    "            insurance_seq = insurance.get(\"sequence\")\n",
    "            print(f\"Insurance seq: {insurance_seq}\")\n",
    "            insurance_focal =insurance.get(\"focal\")\n",
    "            print(f\"Focal: {insurance_focal}\")\n",
    "            insurance_coverage = insurance.get(\"coverage\", {}).get(\"display\")\n",
    "            print(f\"Coverage {insurance_coverage}\")\n",
    "\n",
    "            all_insurances.append({\n",
    "                \"sequence\": insurance_seq,\n",
    "                \"focal\": insurance_focal,\n",
    "                \"coverage\": insurance.get(\"coverage\", {}).get(\"display\")\n",
    "            })\n",
    "        \n",
    "        \n",
    "        items = resource.get(\"items\", [{}])\n",
    "        all_items = []\n",
    "\n",
    "        for item in items:\n",
    "            print(\"Items\")\n",
    "            sequence = \"None\"\n",
    "            sequence = item.get(\"sequence\")\n",
    "            print(f\"Item sequence: {sequence}\")\n",
    "            item_type = \"None\"\n",
    "            diagnosis_seq = \"None\"\n",
    "            diagnosis_seq = item.get(\"diagnosisSequence\")\n",
    "            information_seq = \"None\"\n",
    "            information_seq = item.get(\"informationSequence\")\n",
    "            procedure_seq = \"None\"\n",
    "            procedure_seq = item.get(\"procedureSequence\")\n",
    "            productOrService = item.get(\"productOrService\")\n",
    "            system = \"None\"\n",
    "            code = \"None\"\n",
    "            display = \"None\"\n",
    "            if(productOrService):\n",
    "                coding = productOrService.get(\"coding\")\n",
    "                if coding: \n",
    "                    system = coding[0].get(\"system\")\n",
    "                    print(f\"system: {system}\")\n",
    "                    code = coding[0].get(\"code\")\n",
    "                    print(f\"code: {code}\")\n",
    "                    display = coding[0].get(\"display\")\n",
    "                    print(f\"display: {display}\")\n",
    "            service_period = \"None\"\n",
    "            service_period = item.get(\"servicePeriod\",{})\n",
    "            print(f\"service_period: {service_period}\")\n",
    "            start = \"None\"\n",
    "            end = \"None\"\n",
    "            if(service_period):\n",
    "                start = service_period.get(\"start\")\n",
    "                end = service_period.get(\"end\")\n",
    "                \n",
    "            print(f\"start: {start}\")\n",
    "            print(f\"end: {end}\")\n",
    "\n",
    "            if diagnosis_seq:\n",
    "                item_type = \"diagnosis sequence\"  \n",
    "            if information_seq:\n",
    "                item_type = \"information sequence\"\n",
    "            if procedure_seq:\n",
    "                item_type = \"procedure sequence\"  \n",
    "            print(f\"item_type: {item_type}\")\n",
    "\n",
    "            location = []\n",
    "\n",
    "            location_coding = item.get(\"locationCodeableConcept\",[])\n",
    "            location_system = \"None\"\n",
    "            location_code = \"None\"\n",
    "            location_display = \"None\"\n",
    "\n",
    "            if location_coding:\n",
    "                location_system = location_coding[0].get(\"system\")\n",
    "                location_code = location_coding[0].get(\"code\")\n",
    "                location_display = location_coding[0].get(\"display\")\n",
    "            \n",
    "            '''print(f\"location_system: {location_system}\")\n",
    "            print(f\"location_code: {location_code}\")\n",
    "            print(f\"location_display: {location_display}\")'''\n",
    "\n",
    "            location.append({\n",
    "                \"facility_id\": facility_id,\n",
    "                \"system\": location_system,\n",
    "                \"code\": location_code,\n",
    "                \"display\": location_display\n",
    "            })\n",
    "\n",
    "            print(f\"-------------------location: {location}\")\n",
    "\n",
    "            encounter = None\n",
    "            encounter_array = item.get(\"encounter\",[])\n",
    "            if encounter_array: \n",
    "                encounter = encounter_array[0].get(\"reference\").split(\":\")[-1]\n",
    "            print(f\"encounter:{encounter}\")\n",
    "\n",
    "            net_value = 0\n",
    "            net_currency = \"USD\"\n",
    "            net = item.get(\"net\",{})\n",
    "            if net:\n",
    "                net_value = net.get(\"value\")\n",
    "            print(f\"net_value: {net_value}\")\n",
    "            if net:\n",
    "                net_currency = net.get(\"currency\")\n",
    "            print(f\"net_currency: {net_currency}\")\n",
    "\n",
    "            item_text =item.get(\"text\")\n",
    "            print(f\"item_text: {item_text}\")\n",
    "\n",
    "            all_items.append({\n",
    "                \"sequence\": sequence,\n",
    "                \"item_type\": item_type,\n",
    "                \"system\": system,\n",
    "                \"code\": code,\n",
    "                \"display\": display,\n",
    "                \"service_start\":start,\n",
    "                \"service_end\": end,\n",
    "                \"net_value\": net_value,\n",
    "                \"net_currency\": net_currency,\n",
    "                \"location\": location,\n",
    "                \"encounter\": encounter,\n",
    "                \"start_period\": start,\n",
    "                \"end_period\": end,\n",
    "                \"item_text\": item_text\n",
    "            })\n",
    "\n",
    "        # Initialize columns\n",
    "        #diagnosis_sequence = None\n",
    "        #diagnosis_id = None\n",
    "        #all_diagnosis = [{\"sequence\": None, \"diagnosis\": None}]\n",
    "        '''all_diagnosis = []\n",
    "        diagnoses = resource.get(\"diagnosis\",[])\n",
    "        print(f\"diagnoses {diagnoses}\")\n",
    "\n",
    "        \n",
    "\n",
    "        for diagnosis in diagnoses:\n",
    "            print(\"--------------There are diagnoses.\")\n",
    "            diagnosis_sequence = diagnosis.get(\"sequence\")\n",
    "            diagnosis_id = diagnosis.get(\"diagnosisReference\").get(\"reference\").split(\":\")[-1] #conditions\n",
    "            print(f\"diagnosis: {diagnosis_id}\")\n",
    "            print(f\"sequence: {diagnosis_sequence}\")\n",
    "            all_diagnosis.append({\n",
    "                \"sequence\": diagnosis_sequence,\n",
    "                \"diagnosis\": diagnosis_id   \n",
    "            })\n",
    "        \n",
    "        print(f\"all_diagnosis: {all_diagnosis}\")'''\n",
    "\n",
    "        diagnoses = resource.get(\"diagnosis\", []) or []\n",
    "        all_diagnosis = []\n",
    "\n",
    "        if isinstance(diagnoses, list):\n",
    "            for diagnosis in diagnoses:\n",
    "                diag_ref = diagnosis.get(\"diagnosisReference\", {}).get(\"reference\")\n",
    "                diagnosis_id = diag_ref.split(\":\")[-1] if diag_ref else None\n",
    "                all_diagnosis.append({\n",
    "                    \"sequence\": diagnosis.get(\"sequence\"),\n",
    "                    \"diagnosis\": diagnosis_id\n",
    "                })\n",
    "\n",
    "        # enforce consistent type: always a list (not None, not scalar)\n",
    "        if not all_diagnosis:\n",
    "            all_diagnosis = []\n",
    "\n",
    "        records.append({\n",
    "            \"claim_id\": rid,\n",
    "            \"status\" : status,\n",
    "            \"use\": use,\n",
    "            \"status\": status,\n",
    "            \"patient_id\": patient_id,\n",
    "            \"claim_type_info\": type,\n",
    "            \"total_value\": total_value,\n",
    "            \"total_currency\": total_currency,\n",
    "            \"billable_start\": billable_start,\n",
    "            \"billable_end\" : billable_end,\n",
    "            \"created\": date_created,\n",
    "            #\"billing_provider\": [\n",
    "                #{\n",
    "            \"provider_reference_id\": provider_reference_id,\n",
    "            \"provider_reference_type\": provider_reference_type,\n",
    "            \"provider_display\": provider_display,\n",
    "                #}\n",
    "            #] if provider_reference_id else [],\n",
    "            \"priority_code\": priority_code,\n",
    "            \"date_created\": date_created,\n",
    "            \"facility\": [\n",
    "                {\n",
    "                    \"facility_reference\": facility_reference,\n",
    "                    \"facility_id\": facility_id,\n",
    "                    \"facility_display\" : facility_display \n",
    "                }\n",
    "            ] if facility_json else [],\n",
    "            \"all_insurances\": all_insurances,\n",
    "            \"diagnoses\": all_diagnosis,\n",
    "            \"items\":all_items,\n",
    "            \"load_timestamp\": datetime.now(timezone.utc) \n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "# Main ETL loop\n",
    "def etl_claims():\n",
    "    try:\n",
    "        for batch in fetch_staged_data(\"claims_fhir_raw\"):\n",
    "            df = transform_claims(batch)\n",
    "            if not df.empty:\n",
    "                insert_to_bq(df, \"claims\")\n",
    "                print(\"***Inserted batch***\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in claims ETL: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_claims()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7c250635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 rows to fhir-synthea-data.fhir_curated.claims\n"
     ]
    }
   ],
   "source": [
    "#---Claims ETL\n",
    "import psycopg2\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "import pprint\n",
    "import dateutil.parser  # optional, for robust ISO parsing\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Path to your service account JSON key\n",
    "key_path = \"/Users/toniventura/keys/bq_key.json\"\n",
    "\n",
    "# Create credentials and BigQuery client\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path)\n",
    "BQ_PROJECT = \"fhir-synthea-data\"\n",
    "BQ_DATASET = \"fhir_curated\"\n",
    "client = bigquery.Client(project=BQ_PROJECT, credentials=credentials)\n",
    "\n",
    "# Postgres config\n",
    "PG_CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": 5432,\n",
    "    \"database\": \"fhir\",\n",
    "    \"user\": \"toniventura\",\n",
    "    \"password\": \"fhir_project\"\n",
    "}\n",
    "\n",
    "def insert_to_bq(df, table_name):\n",
    "    table_id = f\"{BQ_PROJECT}.{BQ_DATASET}.{table_name}\"\n",
    "    job = client.load_table_from_dataframe(df, table_id)\n",
    "    job.result()\n",
    "    print(f\"Loaded {job.output_rows} rows to {table_id}\")\n",
    "\n",
    "\n",
    "\n",
    "# Helper: fetch staged data\n",
    "def fetch_staged_data(table, batch_size=10000):\n",
    "    try:\n",
    "        conn = psycopg2.connect(**PG_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(f\"SELECT * FROM fhir_staging.{table} LIMIT 5;\")\n",
    "        while True:\n",
    "            rows = cur.fetchmany(batch_size)\n",
    "            if not rows:\n",
    "                break\n",
    "            yield rows\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Postgres connection or query failed: {e}\")\n",
    "\n",
    "def safe_list_of_structs(input_list, required_keys):\n",
    "    \"\"\"Ensure a list of dicts is PyArrow-safe.\"\"\"\n",
    "    if not input_list or not isinstance(input_list, list):\n",
    "        return [{k: None for k in required_keys}]\n",
    "    cleaned = []\n",
    "    for item in input_list:\n",
    "        if not isinstance(item, dict):\n",
    "            continue\n",
    "        cleaned.append({k: item.get(k, None) for k in required_keys})\n",
    "    return cleaned if cleaned else [{k: None for k in required_keys}]\n",
    "\n",
    "def normalize_list_of_dicts(lst, keys):\n",
    "    \"\"\"Ensure lst is a list of dicts with all keys present, filling missing keys with None.\"\"\"\n",
    "    if not lst or not isinstance(lst, list):\n",
    "        return []\n",
    "    normalized = []\n",
    "    for d in lst:\n",
    "        if not isinstance(d, dict):\n",
    "            continue\n",
    "        normalized.append({k: d.get(k, None) for k in keys})\n",
    "    return normalized\n",
    "\n",
    "def transform_claims_bq(rows):\n",
    "    records = []\n",
    "\n",
    "    for r in rows:\n",
    "        rid, resource = r[1], r[2]\n",
    "\n",
    "        # --- Basic fields ---\n",
    "        use = resource.get(\"use\")\n",
    "        status = resource.get(\"status\")\n",
    "        patient_ref = resource.get(\"patient\", {}).get(\"reference\")\n",
    "        patient_id = patient_ref.split(\":\")[-1] if patient_ref else None\n",
    "\n",
    "        # Claim type\n",
    "        type_info = resource.get(\"type\")\n",
    "        claim_type = None\n",
    "        if isinstance(type_info, dict):\n",
    "            coding = type_info.get(\"coding\")\n",
    "            if coding:\n",
    "                claim_type = coding[0].get(\"code\")\n",
    "        elif isinstance(type_info, list) and type_info:\n",
    "            coding = type_info[0].get(\"coding\")\n",
    "            if coding:\n",
    "                claim_type = coding[0].get(\"code\")\n",
    "\n",
    "        # --- Totals ---\n",
    "        total_value = resource.get(\"total\", {}).get(\"value\")\n",
    "        total_currency = resource.get(\"total\", {}).get(\"currency\")\n",
    "\n",
    "        # --- Dates ---\n",
    "        billable_start = resource.get(\"billablePeriod\", {}).get(\"start\")\n",
    "        billable_end = resource.get(\"billablePeriod\", {}).get(\"end\")\n",
    "        created = resource.get(\"created\")\n",
    "\n",
    "        # --- Provider ---\n",
    "        provider_obj = resource.get(\"provider\") or {}\n",
    "        provider_reference = provider_obj.get(\"reference\")\n",
    "        provider_reference_id = provider_reference.split(\"|\")[-1] if provider_reference else None\n",
    "        provider_reference_type = provider_reference.split(\"?\")[0] if provider_reference and \"?\" in provider_reference else None\n",
    "        provider_display = provider_obj.get(\"display\")\n",
    "\n",
    "        '''billing_provider = safe_list_of_structs(\n",
    "            [{\"provider_reference_id\": provider_id,\n",
    "              \"provider_reference_type\": provider_type,\n",
    "              \"provider_display\": provider_display}],\n",
    "            [\"provider_reference_id\", \"provider_reference_type\", \"provider_display\"]\n",
    "        )'''\n",
    "\n",
    "        # --- Facility ---\n",
    "        facility_json = resource.get(\"facility\") or {}\n",
    "        facility_reference_complete = facility_json.get(\"reference\")\n",
    "        facility_reference = facility_reference_complete.split(\"|\")[0] if facility_reference_complete else None\n",
    "        facility_id = facility_reference_complete.split(\"|\")[-1] if facility_reference_complete else None\n",
    "        facility_display = facility_json.get(\"display\")\n",
    "\n",
    "        facility = []\n",
    "        if facility_json:\n",
    "            facility.append({\n",
    "                \"facility_reference\": facility_reference,\n",
    "                \"facility_id\": facility_id,\n",
    "                \"facility_display\": facility_display\n",
    "            })\n",
    "\n",
    "        # --- Priority ---\n",
    "        priority_codings = resource.get(\"priority\", {}).get(\"coding\", [])\n",
    "        priority_code = priority_codings[0].get(\"code\") if priority_codings else None\n",
    "\n",
    "        # --- Insurance ---\n",
    "        insurances = resource.get(\"insurance\", [])\n",
    "        all_insurances = []\n",
    "        for insurance in insurances:\n",
    "            all_insurances.append({\n",
    "                \"sequence\": insurance.get(\"sequence\"),\n",
    "                \"focal\": insurance.get(\"focal\"),\n",
    "                \"coverage\": insurance.get(\"coverage\", {}).get(\"display\")\n",
    "            })\n",
    "\n",
    "        ## --- Items ---\n",
    "        items = resource.get(\"items\", [])\n",
    "        all_items = []\n",
    "        for item in items:\n",
    "            product = item.get(\"productOrService\", {})\n",
    "            coding = product.get(\"coding\", [{}])[0] if product else {}\n",
    "            location_coding = item.get(\"locationCodeableConcept\", [{}])[0] if item.get(\"locationCodeableConcept\") else {}\n",
    "\n",
    "            encounter_array = item.get(\"encounter\", [])\n",
    "            encounter_ref = encounter_array[0].get(\"reference\").split(\":\")[-1] if encounter_array else None\n",
    "\n",
    "            net = item.get(\"net\", {})\n",
    "            all_items.append({\n",
    "                \"sequence\": item.get(\"sequence\"),\n",
    "                \"item_type\": \"diagnosis sequence\" if item.get(\"diagnosisSequence\") else (\n",
    "                             \"information sequence\" if item.get(\"informationSequence\") else (\n",
    "                             \"procedure sequence\" if item.get(\"procedureSequence\") else None)),\n",
    "                \"system\": coding.get(\"system\"),\n",
    "                \"code\": coding.get(\"code\"),\n",
    "                \"display\": coding.get(\"display\"),\n",
    "                \"service_start\": item.get(\"servicePeriod\", {}).get(\"start\"),\n",
    "                \"service_end\": item.get(\"servicePeriod\", {}).get(\"end\"),\n",
    "                \"net_value\": net.get(\"value\"),\n",
    "                \"net_currency\": net.get(\"currency\"),\n",
    "                \"location\": [{\n",
    "                    \"facility_id\": facility_id,\n",
    "                    \"system\": location_coding.get(\"system\"),\n",
    "                    \"code\": location_coding.get(\"code\"),\n",
    "                    \"display\": location_coding.get(\"display\")\n",
    "                }] if location_coding else [],\n",
    "                \"encounter\": encounter_ref,\n",
    "                \"item_text\": item.get(\"text\")\n",
    "            })\n",
    "\n",
    "         # --- Diagnoses ---\n",
    "        diagnoses = resource.get(\"diagnosis\", []) or []\n",
    "        all_diagnosis = []\n",
    "        for diag in diagnoses:\n",
    "            diag_ref = diag.get(\"diagnosisReference\", {}).get(\"reference\")\n",
    "            diag_id = diag_ref.split(\":\")[-1] if diag_ref else None\n",
    "            all_diagnosis.append({\n",
    "                \"sequence\": diag.get(\"sequence\"),\n",
    "                \"diagnosis\": diag_id\n",
    "            })\n",
    "\n",
    "        # --- Append record ---\n",
    "        records.append({\n",
    "            \"claim_id\": rid,\n",
    "            \"status\": status,\n",
    "            \"use\": use,\n",
    "            \"patient_id\": patient_id,\n",
    "            \"claim_type_info\": claim_type,\n",
    "            \"total_value\": total_value,\n",
    "            \"total_currency\": total_currency,\n",
    "            \"billable_start\": billable_start,\n",
    "            \"billable_end\": billable_end,\n",
    "            \"created\": created,\n",
    "            \"provider_reference_id\": provider_reference_id,\n",
    "            \"provider_reference_type\": provider_reference_type,\n",
    "            \"provider_display\": provider_display,\n",
    "            \"priority_code\": priority_code,\n",
    "            \"facility\": facility,\n",
    "            \"all_insurances\": all_insurances,\n",
    "            \"diagnoses\": all_diagnosis,\n",
    "            \"items\": all_items,\n",
    "            \"load_timestamp\": datetime.now(timezone.utc).isoformat()\n",
    "        })\n",
    "    return records\n",
    "\n",
    "# Main ETL loop\n",
    "def etl_claims():\n",
    "    try:\n",
    "        for batch in fetch_staged_data(\"claims_fhir_raw\"):\n",
    "            '''df = transform_claims(batch)\n",
    "            if not df.empty:\n",
    "                insert_to_bq(df, \"claims\")\n",
    "                print(\"***Inserted batch***\")'''\n",
    "            \n",
    "\n",
    "            table_id = \"fhir-synthea-data.fhir_curated.claims\"\n",
    "\n",
    "        # Define schema (nested fields)\n",
    "        job_config = bigquery.LoadJobConfig(\n",
    "        schema=[\n",
    "            bigquery.SchemaField(\"claim_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "            bigquery.SchemaField(\"status\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"use\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"patient_id\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"claim_type_info\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"total_value\", \"FLOAT\"),\n",
    "            bigquery.SchemaField(\"total_currency\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"billable_start\", \"TIMESTAMP\"),\n",
    "            bigquery.SchemaField(\"billable_end\", \"TIMESTAMP\"),\n",
    "            bigquery.SchemaField(\"created\", \"TIMESTAMP\"),\n",
    "            bigquery.SchemaField(\"provider_reference_id\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"provider_reference_type\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"provider_display\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"priority_code\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"facility\", \"RECORD\", mode=\"REPEATED\", fields=[\n",
    "            bigquery.SchemaField(\"facility_reference\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"facility_id\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"facility_display\", \"STRING\"),\n",
    "        ]),\n",
    "        bigquery.SchemaField(\"all_insurances\", \"RECORD\", mode=\"REPEATED\", fields=[\n",
    "            bigquery.SchemaField(\"sequence\", \"INTEGER\"),\n",
    "            bigquery.SchemaField(\"focal\", \"BOOLEAN\"),\n",
    "            bigquery.SchemaField(\"coverage\", \"STRING\"),\n",
    "        ]),\n",
    "        bigquery.SchemaField(\"diagnoses\",\"RECORD\", mode=\"REPEATED\", fields=[\n",
    "            bigquery.SchemaField(\"sequence\", \"INTEGER\"),\n",
    "            bigquery.SchemaField(\"diagnosis\", \"STRING\"),\n",
    "        ]),\n",
    "        bigquery.SchemaField(\"items\", \"RECORD\", mode=\"REPEATED\", fields=[\n",
    "            bigquery.SchemaField(\"sequence\", \"INTEGER\"),\n",
    "            bigquery.SchemaField(\"item_type\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"system\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"code\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"display\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"service_start\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"service_end\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"net_value\", \"FLOAT\"),\n",
    "            bigquery.SchemaField(\"net_currency\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"location\", \"RECORD\", mode=\"REPEATED\", fields=[\n",
    "                bigquery.SchemaField(\"facility_id\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"system\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"code\", \"STRING\"),\n",
    "                bigquery.SchemaField(\"display\", \"STRING\"),\n",
    "            ]),\n",
    "            bigquery.SchemaField(\"encounter\", \"STRING\"),\n",
    "            bigquery.SchemaField(\"item_text\", \"STRING\"),\n",
    "        ]),\n",
    "        bigquery.SchemaField(\"load_timestamp\", \"TIMESTAMP\", mode=\"REQUIRED\"),\n",
    "        ],\n",
    "        )\n",
    "\n",
    "        # Load data\n",
    "        records = transform_claims_bq(batch)\n",
    "        job = client.load_table_from_json(records, table_id, job_config=job_config)\n",
    "        job.result()\n",
    "        print(f\"Loaded {len(records)} rows to {table_id}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in claims ETL: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl_claims()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
